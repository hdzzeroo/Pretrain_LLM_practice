{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3262d350",
   "metadata": {},
   "source": [
    "# 指令微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5d4f9",
   "metadata": {},
   "source": [
    "### 下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e141950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        text_data = response.text\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bcf794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d59280c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf546994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf1359a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a6ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9cab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6c696",
   "metadata": {},
   "source": [
    "### 定义dataset和dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b301599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c26d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4930cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InstructionDataset(data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc3bdb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.', 'input': 'freind --> friend', 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}\n",
      "{'instruction': 'Edit the following sentence for grammar.', 'input': 'He go to the park every day.', 'output': 'He goes to the park every day.'}\n",
      "{'instruction': 'Convert 45 kilometers to meters.', 'input': '', 'output': '45 kilometers is 45000 meters.'}\n",
      "{'instruction': \"Rewrite this sentence to start with 'Although': Despite the rain, they went for a walk.\", 'input': '', 'output': 'Although it was raining, they went for a walk.'}\n",
      "{'instruction': 'What are the first 10 square numbers?', 'input': '', 'output': '1, 4, 9, 16, 25, 36, 49, 64, 81, 100.'}\n",
      "{'instruction': 'Suggest a more formal synonym for \"happy.\"', 'input': '', 'output': 'A more formal synonym for \"happy\" is \"content.\"'}\n",
      "{'instruction': 'Translate the following sentence into French.', 'input': 'Where is the nearest restaurant?', 'output': 'Où est le restaurant le plus proche?'}\n",
      "{'instruction': 'Look up the melting point of iron.', 'input': '', 'output': 'The melting point of iron is approximately 1538 degrees Celsius or 2800 degrees Fahrenheit.'}\n",
      "{'instruction': 'Rewrite the following sentence so that it is in active voice.', 'input': 'The cake was baked by Sarah.', 'output': 'Sarah baked the cake.'}\n",
      "{'instruction': \"Convert the active sentence to passive: 'The manager approved the project.'\", 'input': '', 'output': 'The project was approved by the manager.'}\n",
      "{'instruction': 'What is the contraction for \"will not\"?', 'input': '', 'output': 'The contraction for \"will not\" is \"won\\'t\".'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df4ff979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 36, 2100, 4985, 262, 1708, 9546, 416, 25449, 340, 656, 262, 24993, 1813, 13, 198, 198, 21017, 23412, 25, 198, 19503, 521, 14610, 1545, 198, 198, 21017, 18261, 25, 198, 464, 24993, 286, 262, 1813, 9546, 366, 19503, 521, 1, 318, 11491, 11, 262, 3376, 24993, 318, 366, 6726, 1911]\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 18378, 262, 1708, 6827, 329, 23491, 13, 198, 198, 21017, 23412, 25, 198, 1544, 467, 284, 262, 3952, 790, 1110, 13, 198, 198, 21017, 18261, 25, 198, 1544, 2925, 284, 262, 3952, 790, 1110, 13]\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 3103, 1851, 4153, 18212, 284, 10700, 13, 198, 198, 21017, 18261, 25, 198, 2231, 18212, 318, 4153, 830, 10700, 13]\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 30003, 6525, 428, 6827, 284, 923, 351, 705, 7003, 10354, 7945, 262, 6290, 11, 484, 1816, 329, 257, 2513, 13, 198, 198, 21017, 18261, 25, 198, 7003, 340, 373, 43079, 11, 484, 1816, 329, 257, 2513, 13]\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 2061, 389, 262, 717, 838, 6616, 3146, 30, 198, 198, 21017, 18261, 25, 198, 16, 11, 604, 11, 860, 11, 1467, 11, 1679, 11, 4570, 11, 5125, 11, 5598, 11, 9773, 11, 1802, 13]\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 43857, 257, 517, 8766, 6171, 5177, 329, 366, 34191, 526, 198, 198, 21017, 18261, 25, 198, 32, 517, 8766, 6171, 5177, 329, 366, 34191, 1, 318, 366, 11299, 526]\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 8291, 17660, 262, 1708, 6827, 656, 4141, 13, 198, 198, 21017, 23412, 25, 198, 8496, 318, 262, 16936, 7072, 30, 198, 198, 21017, 18261, 25, 198, 46, 127, 117, 1556, 443, 7072, 443, 5556, 386, 2395, 30]\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 8567, 510, 262, 24203, 966, 286, 6953, 13, 198, 198, 21017, 18261, 25, 198, 464, 24203, 966, 286, 6953, 318, 6702, 1315, 2548, 7370, 34186, 393, 2579, 405, 7370, 35935, 13]\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 30003, 6525, 262, 1708, 6827, 523, 326, 340, 318, 287, 4075, 3809, 13, 198, 198, 21017, 23412, 25, 198, 464, 12187, 373, 22979, 416, 10490, 13, 198, 198, 21017, 18261, 25, 198, 29284, 22979, 262, 12187, 13]\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 3103, 1851, 262, 4075, 6827, 284, 14513, 25, 705, 464, 4706, 6325, 262, 1628, 2637, 198, 198, 21017, 18261, 25, 198, 464, 1628, 373, 6325, 416, 262, 4706, 13]\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 2061, 318, 262, 36246, 329, 366, 10594, 407, 13984, 198, 198, 21017, 18261, 25, 198, 464, 36246, 329, 366, 10594, 407, 1, 318, 366, 26502, 470, 1911]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset)):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(dataset[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bccbc7",
   "metadata": {},
   "source": [
    "定义对每一批数据执行某些操作的函数，填充和添加-100，而防止模型学习填充的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d259233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra\n",
    "    # padding token below\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Via padded[:-1], we remove the extra padded token\n",
    "        # that has been added via the +1 setting in batch_max_length\n",
    "        # (the extra padding token will be relevant in later codes)\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddcbe618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,\n",
      "           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,\n",
      "         21017, 23412,    25,   198, 19503,   521, 14610,  1545,   198,   198,\n",
      "         21017, 18261,    25,   198,   464, 24993,   286,   262,  1813,  9546,\n",
      "           366, 19503,   521,     1,   318, 11491,    11,   262,  3376, 24993,\n",
      "           318,   366,  6726,  1911],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
      "            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
      "           262,  3952,   790,  1110,    13,   198,   198, 21017, 18261,    25,\n",
      "           198,  1544,  2925,   284,   262,  3952,   790,  1110,    13, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,  4153, 18212,   284, 10700,\n",
      "            13,   198,   198, 21017, 18261,    25,   198,  2231, 18212,   318,\n",
      "          4153,   830, 10700,    13, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256]])\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
      "            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
      "           262,  3952,   790,  1110,    13,   198,   198, 21017, 18261,    25,\n",
      "           198,  1544,  2925,   284,   262,  3952,   790,  1110,    13, 50256,\n",
      "         50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,  4153, 18212,   284, 10700,\n",
      "            13,   198,   198, 21017, 18261,    25,   198,  2231, 18212,   318,\n",
      "          4153,   830, 10700,    13, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198, 30003,  6525,   428,  6827,   284,   923,\n",
      "           351,   705,  7003, 10354,  7945,   262,  6290,    11,   484,  1816,\n",
      "           329,   257,  2513,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          7003,   340,   373, 43079,    11,   484,  1816,   329,   257,  2513,\n",
      "            13]])\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,  4153, 18212,   284, 10700,\n",
      "            13,   198,   198, 21017, 18261,    25,   198,  2231, 18212,   318,\n",
      "          4153,   830, 10700,    13, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198, 30003,  6525,   428,  6827,   284,   923,\n",
      "           351,   705,  7003, 10354,  7945,   262,  6290,    11,   484,  1816,\n",
      "           329,   257,  2513,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          7003,   340,   373, 43079,    11,   484,  1816,   329,   257,  2513,\n",
      "            13],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  2061,   389,   262,   717,   838,  6616,\n",
      "          3146,    30,   198,   198, 21017, 18261,    25,   198,    16,    11,\n",
      "           604,    11,   860,    11,  1467,    11,  1679,    11,  4570,    11,\n",
      "          5125,    11,  5598,    11,  9773,    11,  1802,    13, 50256, 50256,\n",
      "         50256]])\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198, 30003,  6525,   428,  6827,   284,   923,\n",
      "           351,   705,  7003, 10354,  7945,   262,  6290,    11,   484,  1816,\n",
      "           329,   257,  2513,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          7003,   340,   373, 43079,    11,   484,  1816,   329,   257,  2513,\n",
      "            13],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  2061,   389,   262,   717,   838,  6616,\n",
      "          3146,    30,   198,   198, 21017, 18261,    25,   198,    16,    11,\n",
      "           604,    11,   860,    11,  1467,    11,  1679,    11,  4570,    11,\n",
      "          5125,    11,  5598,    11,  9773,    11,  1802,    13, 50256, 50256,\n",
      "         50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198, 43857,   257,   517,  8766,  6171,  5177,\n",
      "           329,   366, 34191,   526,   198,   198, 21017, 18261,    25,   198,\n",
      "            32,   517,  8766,  6171,  5177,   329,   366, 34191,     1,   318,\n",
      "           366, 11299,   526, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256]])\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  2061,   389,   262,   717,   838,  6616,\n",
      "          3146,    30,   198,   198, 21017, 18261,    25,   198,    16,    11,\n",
      "           604,    11,   860,    11,  1467,    11,  1679,    11,  4570,    11,\n",
      "          5125,    11,  5598,    11,  9773,    11,  1802,    13, 50256, 50256,\n",
      "         50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198, 43857,   257,   517,  8766,  6171,  5177,\n",
      "           329,   366, 34191,   526,   198,   198, 21017, 18261,    25,   198,\n",
      "            32,   517,  8766,  6171,  5177,   329,   366, 34191,     1,   318,\n",
      "           366, 11299,   526, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  8291, 17660,   262,  1708,  6827,   656,\n",
      "          4141,    13,   198,   198, 21017, 23412,    25,   198,  8496,   318,\n",
      "           262, 16936,  7072,    30,   198,   198, 21017, 18261,    25,   198,\n",
      "            46,   127,   117,  1556,   443,  7072,   443,  5556,   386,  2395,\n",
      "            30]])\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198, 43857,   257,   517,  8766,  6171,  5177,\n",
      "           329,   366, 34191,   526,   198,   198, 21017, 18261,    25,   198,\n",
      "            32,   517,  8766,  6171,  5177,   329,   366, 34191,     1,   318,\n",
      "           366, 11299,   526, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  8291, 17660,   262,  1708,  6827,   656,\n",
      "          4141,    13,   198,   198, 21017, 23412,    25,   198,  8496,   318,\n",
      "           262, 16936,  7072,    30,   198,   198, 21017, 18261,    25,   198,\n",
      "            46,   127,   117,  1556,   443,  7072,   443,  5556,   386,  2395,\n",
      "            30],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  8567,   510,   262, 24203,   966,   286,\n",
      "          6953,    13,   198,   198, 21017, 18261,    25,   198,   464, 24203,\n",
      "           966,   286,  6953,   318,  6702,  1315,  2548,  7370, 34186,   393,\n",
      "          2579,   405,  7370, 35935,    13, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256]])\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  8291, 17660,   262,  1708,  6827,   656,\n",
      "          4141,    13,   198,   198, 21017, 23412,    25,   198,  8496,   318,\n",
      "           262, 16936,  7072,    30,   198,   198, 21017, 18261,    25,   198,\n",
      "            46,   127,   117,  1556,   443,  7072,   443,  5556,   386,  2395,\n",
      "            30],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  8567,   510,   262, 24203,   966,   286,\n",
      "          6953,    13,   198,   198, 21017, 18261,    25,   198,   464, 24203,\n",
      "           966,   286,  6953,   318,  6702,  1315,  2548,  7370, 34186,   393,\n",
      "          2579,   405,  7370, 35935,    13, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   523,\n",
      "           326,   340,   318,   287,  4075,  3809,    13,   198,   198, 21017,\n",
      "         23412,    25,   198,   464, 12187,   373, 22979,   416, 10490,    13,\n",
      "           198,   198, 21017, 18261,    25,   198, 29284, 22979,   262, 12187,\n",
      "            13]])\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  8567,   510,   262, 24203,   966,   286,\n",
      "          6953,    13,   198,   198, 21017, 18261,    25,   198,   464, 24203,\n",
      "           966,   286,  6953,   318,  6702,  1315,  2548,  7370, 34186,   393,\n",
      "          2579,   405,  7370, 35935,    13, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   523,\n",
      "           326,   340,   318,   287,  4075,  3809,    13,   198,   198, 21017,\n",
      "         23412,    25,   198,   464, 12187,   373, 22979,   416, 10490,    13,\n",
      "           198,   198, 21017, 18261,    25,   198, 29284, 22979,   262, 12187,\n",
      "            13],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464,  4706,  6325,   262,  1628,  2637,   198,\n",
      "           198, 21017, 18261,    25,   198,   464,  1628,   373,  6325,   416,\n",
      "           262,  4706,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256]])\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   523,\n",
      "           326,   340,   318,   287,  4075,  3809,    13,   198,   198, 21017,\n",
      "         23412,    25,   198,   464, 12187,   373, 22979,   416, 10490,    13,\n",
      "           198,   198, 21017, 18261,    25,   198, 29284, 22979,   262, 12187,\n",
      "            13],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464,  4706,  6325,   262,  1628,  2637,   198,\n",
      "           198, 21017, 18261,    25,   198,   464,  1628,   373,  6325,   416,\n",
      "           262,  4706,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  2061,   318,   262, 36246,   329,   366,\n",
      "         10594,   407, 13984,   198,   198, 21017, 18261,    25,   198,   464,\n",
      "         36246,   329,   366, 10594,   407,     1,   318,   366, 26502,   470,\n",
      "          1911, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256]])\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464,  4706,  6325,   262,  1628,  2637,   198,\n",
      "           198, 21017, 18261,    25,   198,   464,  1628,   373,  6325,   416,\n",
      "           262,  4706,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  2061,   318,   262, 36246,   329,   366,\n",
      "         10594,   407, 13984,   198,   198, 21017, 18261,    25,   198,   464,\n",
      "         36246,   329,   366, 10594,   407,     1,   318,   366, 26502,   470,\n",
      "          1911, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   284,\n",
      "          4781, 49052,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "          4036,  1109,   318,   326,   339,   373,  2739,    13,   198,   198,\n",
      "         21017, 18261,    25,   198,   464,  1109,   318,   326,   339,   373,\n",
      "          2739,    13]])\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  2061,   318,   262, 36246,   329,   366,\n",
      "         10594,   407, 13984,   198,   198, 21017, 18261,    25,   198,   464,\n",
      "         36246,   329,   366, 10594,   407,     1,   318,   366, 26502,   470,\n",
      "          1911, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   284,\n",
      "          4781, 49052,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "          4036,  1109,   318,   326,   339,   373,  2739,    13,   198,   198,\n",
      "         21017, 18261,    25,   198,   464,  1109,   318,   326,   339,   373,\n",
      "          2739,    13],\n",
      "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  2061,   318,   262,  3139,   286, 16256,\n",
      "            30,   198,   198, 21017, 18261,    25,   198,   464,  3139,   286,\n",
      "         16256,   318, 49251,    13, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset)):\n",
    "    if i > 10:\n",
    "        break\n",
    "    batch = (dataset[i], dataset[i+1], dataset[i+2])\n",
    "    print(custom_collate_draft_1(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "795f8890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "063c01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7b8a537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]]), tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]]))\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_2(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70cc8d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length = None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        \n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "769b656f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]]), tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]]))\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_fn(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05fbb31",
   "metadata": {},
   "source": [
    "小实验，说明为什么要加入-100，计算交叉熵的时候会把-100忽略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f78da5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40a23084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ba9d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b0e9f",
   "metadata": {},
   "source": [
    "### 创建dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb53b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# 定义device \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f62b273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985dc2db",
   "metadata": {},
   "source": [
    "这里的collate_fn是dataloader里面自带的一个自定义选项，意义是让dataloader如何打包dataset成一个batch，默认为堆叠，但是例如上面需要padding的情况的话，可以进行自定义来规定打包方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "493c54ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "828c1e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f56e5f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14184ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
       "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
       "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
       "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d19b428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
       "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
       "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
       "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
       "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
       "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902f599",
   "metadata": {},
   "source": [
    "### 加载一个预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8b5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 68.9kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.09MiB/s]\n",
      "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 63.1kiB/s]\n",
      "model.ckpt.data-00000-of-00001:  31%|███▏      | 444M/1.42G [01:59<04:01, 4.04MiB/s]  "
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "# If the `previous_chapters.py` file is not available locally,\n",
    "# you can import it from the `llms-from-scratch` PyPI package.\n",
    "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# E.g.,\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "# from llms_from_scratch.ch05 import download_and_load_gpt2, load_weights_into_gpt\n",
    "\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd336c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
